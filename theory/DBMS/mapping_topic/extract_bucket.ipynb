{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccda5286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 8 words\n",
    "import os\n",
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "\n",
    "model_merged_ngram = BERTopic.load(\"../model_merged_ngram_len_2\")\n",
    "# Create an empty DataFrame to store the topic data\n",
    "topic_data = pd.DataFrame(columns=[\"Bucket Number\", \"Bucket\"])\n",
    "\n",
    "# Define a function to add topic data to the DataFrame\n",
    "def add_topic_data(model, topic_id, dataframe, max_words=8):\n",
    "    words_with_weights = model.get_topic(topic_id)\n",
    "    if words_with_weights:\n",
    "        words = [word for word, _ in words_with_weights[:max_words]]  # Limit to the first 8 words\n",
    "        topic_data.loc[topic_id] = [topic_id, \", \".join(words)]  # Separating words with commas\n",
    "\n",
    "# Iterate over each topic, including -1, and add the topic data to the DataFrame\n",
    "num_topics = len(model_merged_ngram.get_topic_freq().index)\n",
    "for topic_id in range(-1, num_topics - 1):  # Adjust the range to include -1\n",
    "    add_topic_data(model_merged_ngram, topic_id, topic_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "topic_data.to_csv(\"dbms_bucket_new.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6efdea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 10 words\n",
    "import os\n",
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "\n",
    "model_merged_ngram = BERTopic.load(\"../model_merged_ngram_len_2\")\n",
    "os.chdir(\"mapping_topic\")\n",
    "# Create an empty DataFrame to store the topic data\n",
    "topic_data = pd.DataFrame(columns=[\"Bucket Number\", \"Bucket\"])\n",
    "\n",
    "# Define a function to add topic data to the DataFrame\n",
    "def add_topic_data(model, topic_id, dataframe):\n",
    "    words_with_weights = model.get_topic(topic_id)\n",
    "    if words_with_weights:\n",
    "        words = [word for word, _ in words_with_weights]\n",
    "        topic_data.loc[topic_id] = [topic_id, \", \".join(words)]  # Separating words with commas\n",
    "\n",
    "# Iterate over each topic, including -1, and add the topic data to the DataFrame\n",
    "num_topics = len(model_merged_ngram.get_topic_freq().index)\n",
    "for topic_id in range(-1, num_topics - 1):  # Adjust the range to include -1\n",
    "    add_topic_data(model_merged_ngram, topic_id, topic_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "topic_data.to_csv(\"dbms_bucket_new10.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
